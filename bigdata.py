# -*- coding: utf-8 -*-
"""bigdata.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_hIA22RCaNtYev7qz-pqrwYmfwxw0Fuz
"""

!apt-get update
!apt-get install openjdk-8-jdk-headless -qq > /dev/null
!wget -q http://archive.apache.org/dist/spark/spark-3.1.1/spark-3.1.1-bin-hadoop3.2.tgz
!tar xf spark-3.1.1-bin-hadoop3.2.tgz
!pip install -q findspark

import os
os.environ["JAVA_HOME"] = "/usr/lib/jvm/java-8-openjdk-amd64"
os.environ["SPARK_HOME"] = "/content/spark-3.1.1-bin-hadoop3.2"

import findspark
findspark.init()

import pyspark
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from pyspark.sql.functions import *
from pyspark.sql.types import *
from pyspark.sql.functions import rand, randn
from pyspark.ml.clustering import KMeans

from pyspark.sql import SparkSession
spark = SparkSession.builder.appName('k_means').getOrCreate()

df=spark.read.csv('/content/heart.csv',inferSchema=True,header=True)

df.show()

print((df.count(),len(df.columns)))

df.orderBy(rand()).show(10,False)

df.groupBy('age').count().orderBy('count',ascending=False).show(10,False)

from pyspark.ml.linalg import Vectors
from pyspark.ml.feature import VectorAssembler

input_cols=['sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang','oldpeak','slope','ca','thal','target']


# Transform all features into a vector using VectorAssembler
vec_assembler = VectorAssembler(inputCols = input_cols, outputCol='Target')
final_data = vec_assembler.transform(df)
final_data.show()

from pyspark.ml.feature import StandardScaler

scaler = StandardScaler(inputCol="features",
                        outputCol="scaled_feat",
                        withStd = True,
                        withMean=False)

scaled_model = scaler.fit(final_data)

from pyspark.ml.clustering import KMeans
from pyspark.ml.evaluation import ClusteringEvaluator
silhouette_score=[]
evaluator = ClusteringEvaluator(predictionCol='prediction', featuresCol='features', metricName='silhouette', distanceMeasure='squaredEuclidean')
for i in range(2,11):
    KMeans_algo=KMeans(featuresCol='features', k=i)
    KMeans_fit=KMeans_algo.fit(final_data)
    output=KMeans_fit.transform(final_data)
    score=evaluator.evaluate(output)

    silhouette_score.append(score)

    print("Silhouette Score:",score)